# Data Warehouse and Analytics Project

Welcome to the Data Warehouse and Analytics Project repository! ğŸš€
This project demonstrates a comprehensive data warehousing and analytics solution, from building a data warehouse to generating actionable insights. Designed as a portfolio project, it highlights industry best practices in data engineering and analytics.

## ğŸ—ï¸ Data Architecture
The data architecture for this project follows Medallion Architecture Bronze, Silver, and Gold layers:
![Data Architecture](https://github.com/user-attachments/assets/7507c526-d1f5-4cb1-82b4-14e051c05280)
1. __Bronze Layer__: Stores raw data as-is from the source systems. Data is ingested from CSV Files into a SQL Server Database.
2. __Silver Layer__: This layer includes data cleansing, standardization, and normalization processes to prepare data for analysis.
3. __Gold Layer__: Houses business-ready data modeled into a star schema required for reporting and analytics.


## ğŸ“– Project Overview

This project involves:

Data Architecture: Designing a Modern Data Warehouse Using Medallion Architecture Bronze, Silver, and Gold layers.
ETL Pipelines: Extracting, transforming, and loading data from source systems into the warehouse.
Data Modeling: Developing fact and dimension tables optimized for analytical queries.
Analytics & Reporting: Creating SQL-based reports and dashboards for actionable insights.
ğŸ¯ This repository is an excellent resource for professionals and students looking to showcase expertise in:

* SQL Development
* Data Architect
* Data Engineering
* ETL Pipeline Developer
* Data Modeling
* Data Analytics

## ğŸš€ Project Requirements
### Building the Data Warehouse (Data Engineering)
**Objective** 

Develop a modern data warehouse using SQL Server to consolidate sales data, enabling analytical reporting and informed decision-making.

__Specifications__
* Data Sources: Import data from two source systems (ERP and CRM) provided as CSV files.
* Data Quality: Cleanse and resolve data quality issues prior to analysis.
* Integration: Combine both sources into a single, user-friendly data model designed for analytical queries.
* Scope: Focus on the latest dataset only; historization of data is not required.
* Documentation: Provide clear documentation of the data model to support both business stakeholders and analytics teams.
